{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 접근 방식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline의 Randomforest 지도학습 결과를 보았을 때 0.997 정도의 매우 높은 성능을 보여 Level7만 잘 구별한다면 좋은 성능을 얻을 수 있을 것이라고 생각했습니다.\n",
    "\n",
    "7을 구별하기 위해서 비지도 학습으로 접근을 시도했고 오토인코더, one-class-svm, isolated-randomforest 등의 비지도 학습 방법을 적용해 보았으나 기존과 단어 몇개만 다른 경우들이 7에 있어서 인지 성능이 좋지 않았습니다. 그 중에서 오토인코더가 성능이 괜찮았는데 나중에 따로 \"렛서펜더\"님이 오토인코더 관련 코드를 공유해 주실 예정입니다.\n",
    "\n",
    "결론적으로 로그 데이터의 전처리를 진행하고 Baseline에서 Validation을 통해 등급별로 threshold를 상세 설정한 점수가 가장 높게 나왔습니다. Validation으로 주어진 Level 7 이외에도 7로 추정되는 문장들을 추가로 threshold로 잡아주었는데 7로 추정한 방식은 아래의 링크에 설명되어 있습니다.\n",
    "\n",
    "[참고]  \n",
    "https://dacon.io/competitions/official/235717/codeshare/2536?page=1&dtype=recent (대회 베이스라인)  \n",
    "https://dacon.io/competitions/official/235717/codeshare/2539?page=1&dtype=recent (10duck 님의 데이터 전처리 및 EDA)  \n",
    "https://dacon.io/competitions/official/235717/support/403102?page=1&dtype=recent (taegu 님의 threshold 조정 문의 글)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data & Libaray IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import pandas as pds\n",
    "from dask import dataframe\n",
    "import re\n",
    "import numpy as np\n",
    "import seaborn as sbn\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test= pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1418916"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n",
    "### 1. 다양한 기호 및 숫자 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lit = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "def mask(tt):\n",
    "    tt=tt.apply(lambda x: re.sub(r'(\\\\n)',' ',x))\n",
    "    tt=tt.apply(lambda x: re.sub(r'[^a-zA-Zㄱ-ㅣ가-힣0-9:=\\s\\(\\)./,\\<\\>]+',' ',x))\n",
    "    #tt=tt.apply(lambda x: re.sub(r' ?(?P<note>[:=\\(\\)./,\\<\\>]) ?', ' \\g<note> ', x))\n",
    "    tt=tt.apply(lambda x: re.sub(r'[0-9]+',' ',x))\n",
    "    tt=tt.apply(lambda x: re.sub(r\"':/()\",' ',x))\n",
    "    tt=tt.apply(lambda x: re.sub(r':',' ',x))\n",
    "    tt=tt.apply(lambda x: re.sub(r',',' ',x))\n",
    "    # = tt.apply(lambda x: re.sub(r'(',' ',x))\n",
    "    #t = tt.apply(lambda x: re.sub(r')',' ',x))\n",
    "    tt=tt.apply(lambda x: re.sub(r'[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》]',' ',x))\n",
    "    for st in lit:\n",
    "        st = \" \"+st + \" \"\n",
    "        tt=tt.apply(lambda x: re.sub(st,' ',x))\n",
    "    tt=tt.apply(lambda x: re.sub(r'\\s+',' ',x))\n",
    "    \n",
    "    return tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['pre_log'] = mask(train.full_log)\n",
    "test['pre_log'] = mask(test.full_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 영어 단어가 아니거나 3글자 미만인지인 경우에는 삭제\n",
    "+ 단어가 영어단어가 아니거나 3글자 미만이면 False 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#포함되어 있는 단어 모음 생성\n",
    "def count_word(data):\n",
    "    tem = list(data['pre_log'].str.split(\" \"))\n",
    "    all_word = []\n",
    "    for word in tem:\n",
    "        all_word.extend(word)\n",
    "    words = pd.Series(all_word)\n",
    "    return words.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_count = count_word(train)\n",
    "test_count = count_word(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_words = list(set(train_count.index))\n",
    "test_words = list(set(test_count.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#영어 단어 + 3글자 이상인 경우만 True\n",
    "from nltk.corpus import words\n",
    "def check_words(word_list: list):\n",
    "    re = [False] * len(word_list)\n",
    "    for i,word in enumerate(word_list):\n",
    "        if len(word) < 3:\n",
    "            continue\n",
    "        word = word.lower()\n",
    "        if word in words.words():\n",
    "            re[i] = True\n",
    "    return re\n",
    "\n",
    "word_list = ['Promiscuous', 'ab', 'nihongo', 'abstract', 'pedo','gid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, False, False, True, False, True]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check_words는 단어인지를 확인해주고 결과를 t/f로 반환\n",
    "check_words(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tf = check_words(train_words)\n",
    "test_tf = check_words(test_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#단어인지 확인해주는 딕셔너리 만들어주기 (train_isword,test_isword)\n",
    "train_isword = dict()\n",
    "test_isword = dict()\n",
    "\n",
    "total_words = list(train_words)\n",
    "test_words = list(test_words)\n",
    "\n",
    "for i in range(len(train_words)):\n",
    "    train_isword[train_words[i].lower()] = train_tf[i]\n",
    "    \n",
    "for i in range(len(test_words)):\n",
    "    test_isword[test_words[i].lower()] = test_tf[i]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train, Test 에 각각 적용\n",
    "##### 같은 결과이지만 시간 측면에서 아래의 방법을 선택했습니다. (위는 주석 처리)\n",
    "- 모든 문장에 개별적으로 접근하여 영어가 아닌 단어를 제거하는 코드 (약 3~4일)\n",
    "- 미리 사용된 단어들을 모아서 딕셔너리를 만들어서 사용한 경우(약 10분)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def checking_train(data):\n",
    "    re = [False] * len(data)\n",
    "    for i,word in enumerate(data):\n",
    "        if train_isword[word]:\n",
    "            re[i] = True\n",
    "    return re\n",
    "\n",
    "\n",
    "def checking_test(data):\n",
    "    re = [False] * len(data)\n",
    "    for i,word in enumerate(data):\n",
    "        if test_isword[word]:\n",
    "            re[i] = True\n",
    "    return re\n",
    "\n",
    "\n",
    "\n",
    "def cutt_train(data):\n",
    "    data = data.lower()\n",
    "    splited = data.split(\" \")\n",
    "    check = checking_train(splited)\n",
    "    c = np.array(splited)\n",
    "    real_words = list(c[check])    \n",
    "    tem = \" \".join(real_words)\n",
    "    #tem = tem.lower() \n",
    "    return tem\n",
    "\n",
    "def cutt_test(data):\n",
    "    data = data.lower()\n",
    "    splited = data.split(\" \")\n",
    "    check = checking_test(splited)\n",
    "    c = np.array(splited)\n",
    "    real_words = list(c[check])  \n",
    "    tem = \" \".join(real_words)\n",
    "    #tem = tem.lower()\n",
    "    return tem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['cut'] = train['pre_log'].map(cutt_train)\n",
    "test['cut'] = test['pre_log'].map(cutt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train['full_log']\n",
    "del test['full_log']\n",
    "\n",
    "del train['pre_log']\n",
    "del test['pre_log']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train.to_csv(\"sub_train3.csv\",index=False)\n",
    "test.to_csv(\"sub_test3.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train.to_csv(\"only_train.csv\",index =False)\n",
    "test.to_csv(\"only_test.csv\",index =False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 나중에 사용될 inornot 리스트\n",
    "\n",
    "train 데이터에 100퍼센트 동일한 문장이 있는지 확인해주는 변수 입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bag = train['cut'].unique()\n",
    "len(train_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inornot을 통해서 train안에 같은 문장이 있으면 0 없으면 1\n",
    "from tqdm import tqdm\n",
    "inornot = np.zeros(len(test))\n",
    "for i in tqdm(range(len(test))):\n",
    "    tem = test.iloc[i]['cut']\n",
    "    if tem not in train_bag:\n",
    "        inornot[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train = pd.read_csv(\"sub_train3.csv\")\n",
    "test= pd.read_csv(\"sub_test3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>level</th>\n",
       "      <th>cut</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>type error warning collection level error erro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>action with response code type unavailable exc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>type error warning collection level error erro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>type error warning collection level error erro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>type audit arch success yes exit gid suid none...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>type audit arch success yes exit gid suid none...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>type error warning collection level error erro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>warn resurrect connection dead instance but go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>type error warning collection level error erro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>type log warning message error living share no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>type audit arch success yes exit gid suid none...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>type error warning collection level error erro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>warn resurrect connection dead instance but go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>type error warning collection level error erro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>rufus error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>type audit arch success yes exit gid suid none...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>start unable open file file read time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>type error warning collection level error erro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>type error warning collection level error erro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>type error warning collection level error erro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  level                                                cut\n",
       "0    0      0  type error warning collection level error erro...\n",
       "1    1      0  action with response code type unavailable exc...\n",
       "2    2      0  type error warning collection level error erro...\n",
       "3    3      0  type error warning collection level error erro...\n",
       "4    4      1  type audit arch success yes exit gid suid none...\n",
       "5    5      1  type audit arch success yes exit gid suid none...\n",
       "6    6      0  type error warning collection level error erro...\n",
       "7    7      0  warn resurrect connection dead instance but go...\n",
       "8    8      0  type error warning collection level error erro...\n",
       "9    9      0  type log warning message error living share no...\n",
       "10  10      1  type audit arch success yes exit gid suid none...\n",
       "11  11      0  type error warning collection level error erro...\n",
       "12  12      0  warn resurrect connection dead instance but go...\n",
       "13  13      0  type error warning collection level error erro...\n",
       "14  14      0                                        rufus error\n",
       "15  15      1  type audit arch success yes exit gid suid none...\n",
       "16  16      0              start unable open file file read time\n",
       "17  17      0  type error warning collection level error erro...\n",
       "18  18      0  type error warning collection level error erro...\n",
       "19  19      0  type error warning collection level error erro..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>level</th>\n",
       "      <th>cut</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>type error warning collection level error erro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>action with response code type unavailable exc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>type error warning collection level error erro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>type error warning collection level error erro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>type audit arch success yes exit gid suid none...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472967</th>\n",
       "      <td>472967</td>\n",
       "      <td>0</td>\n",
       "      <td>error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472968</th>\n",
       "      <td>472968</td>\n",
       "      <td>1</td>\n",
       "      <td>type audit arch success yes exit gid suid none...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472969</th>\n",
       "      <td>472969</td>\n",
       "      <td>0</td>\n",
       "      <td>type log error task manager message poll for w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472970</th>\n",
       "      <td>472970</td>\n",
       "      <td>0</td>\n",
       "      <td>type error warning collection level error erro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472971</th>\n",
       "      <td>472971</td>\n",
       "      <td>0</td>\n",
       "      <td>type error warning collection level error erro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>472972 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  level                                                cut\n",
       "0            0      0  type error warning collection level error erro...\n",
       "1            1      0  action with response code type unavailable exc...\n",
       "2            2      0  type error warning collection level error erro...\n",
       "3            3      0  type error warning collection level error erro...\n",
       "4            4      1  type audit arch success yes exit gid suid none...\n",
       "...        ...    ...                                                ...\n",
       "472967  472967      0                                              error\n",
       "472968  472968      1  type audit arch success yes exit gid suid none...\n",
       "472969  472969      0  type log error task manager message poll for w...\n",
       "472970  472970      0  type error warning collection level error erro...\n",
       "472971  472971      0  type error warning collection level error erro...\n",
       "\n",
       "[472972 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#train_idx = train[train['cut'] == '']['cut'].index\n",
    "#test_idx = test[test['cut'] == '']['cut'].index\n",
    "\n",
    "#train['cut'].iloc[train_idx] = np.nan\n",
    "#test['cut'].iloc[train_idx] = np.nan\n",
    "\n",
    "#남은 단어가 없는 경우에는 'missing' 으로 대체해주었습니다.\n",
    "train['cut'] = train['cut'].replace('','missing',regex=True)\n",
    "test['cut'] = test['cut'].replace('','missing',regex=True)\n",
    "\n",
    "\n",
    "\n",
    "train = train.fillna(\"missing\")\n",
    "test = test.fillna(\"missing\")\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text=list(train['cut'])\n",
    "train_level=np.array(train['level'])\n",
    "\n",
    "test_text=list(test['cut'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer=CountVectorizer(analyzer=\"word\", max_features=20000)\n",
    "train_features=vectorizer.fit_transform(train_text)\n",
    "test_features=vectorizer.transform(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest=RandomForestClassifier(n_estimators=100,random_state = 1 )\n",
    "forest.fit(train_features,train_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=forest.predict(test_features)\n",
    "results_proba=forest.predict_proba(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[np.where((np.max(results_proba, axis=1)<0.5) & (results == 0))[0]]=7\n",
    "results[np.where((np.max(results_proba, axis=1)<0.5) & (results == 1))[0]]=7\n",
    "results[np.where((np.max(results_proba, axis=1)<0.58) & (results == 2))[0]]=7\n",
    "results[np.where((np.max(results_proba, axis=1)<0.95) & (results == 3))[0]]=7\n",
    "results[np.where((np.max(results_proba, axis=1)<0.58) & (results == 4))[0]]=7\n",
    "results[np.where((np.max(results_proba, axis=1)<0.58) & (results == 5))[0]]=7\n",
    "results[np.where((np.max(results_proba, axis=1)<0.58) & (results == 6))[0]]=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[np.where((np.max(results_proba, axis=1)<0.94001) & (np.max(results_proba, axis=1) > 0.93999) & (results == 1))[0]]=7 #929로 바꿔보기\n",
    "results[np.where((np.max(results_proba, axis=1)<0.611657) & (np.max(results_proba, axis=1) > 0.6116568) & (results == 0))[0]]=7\n",
    "results[np.where((np.max(results_proba, axis=1)<0.571657) & (np.max(results_proba, axis=1) > 0.5716568) & (results == 0))[0]]=7 # \n",
    "results[np.where((np.max(results_proba, axis=1)<0.68001) & (np.max(results_proba, axis=1) > 0.67999) & (results == 5))[0]]=7 #Prevent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 결과 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1002369\n",
       "1     396443\n",
       "3      12813\n",
       "5       6418\n",
       "7        780\n",
       "4         34\n",
       "2         34\n",
       "6         25\n",
       "Name: level, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission=pd.read_csv('sample_submission.csv')\n",
    "submission['level']=results\n",
    "submission['level'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"tem_answer.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 추가작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['inornot'] = pd.Series(inornot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal = test_ans[(test_ans['level']==7) & (test_ans['inornot'] == 0)].index\n",
    "not7_id = list(test.iloc[cal]['id'])\n",
    "pd.Series(not7_id).to_csv(\"not7_id.csv\",index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 추가 작업\n",
    "\n",
    "위의 방식으로 많이 전처리를 하면 7을 걸러내기 위한 threshold 를 잡기는 유리하지만, 지도 학습 그 자체의 성능은 떨어지는 것을 확인 하였습니다. 따라서, 7를 제외한 나머지 등급에는 전처리가 덜 진행된 Data로 지도학습 분류를 하였습니다. TfidfVectorizer 를 사용했습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('train.csv')\n",
    "test=pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['full_log']=train['full_log'].str.replace(r'[0-9]', '<num>')\n",
    "test['full_log']=test['full_log'].str.replace(r'[0-9]', '<num>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train[train['full_log'] == '']['cut'] = np.nan\n",
    "#test[test['full_log'] == '']['cut'] = np.nan\n",
    "#train['cut'] = train['cut'].replace('','missing',regex=True)\n",
    "#test['cut'] = test['cut'].replace('','missing',regex=True)\n",
    "\n",
    "\n",
    "train = train.fillna(\"missing\")\n",
    "test = test.fillna(\"missing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text=list(train['full_log'])\n",
    "train_level=np.array(train['level'])\n",
    "\n",
    "test_text=list(test['full_log'])\n",
    "#ids=list(test['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer=TfidfVectorizer(analyzer=\"word\", max_features=20000)\n",
    "train_features=vectorizer.fit_transform(train_text)\n",
    "test_features=vectorizer.transform(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest=RandomForestClassifier(n_estimators=100,random_state = 1 )\n",
    "forest.fit(train_features,train_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=forest.predict(test_features)\n",
    "results_proba=forest.predict_proba(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1002770\n",
       "1     396532\n",
       "3      12997\n",
       "5       6524\n",
       "4         34\n",
       "2         34\n",
       "6         25\n",
       "Name: level, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission=pd.read_csv('sample_submission.csv')\n",
    "submission['level']=results\n",
    "submission['level'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "not7_id = pd.read_csv('not7_id.csv')\n",
    "not7_id = list(not7_id['0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "780\n",
      "581\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    1002512\n",
       "1     396348\n",
       "3      12915\n",
       "5       6467\n",
       "7        581\n",
       "4         34\n",
       "2         34\n",
       "6         25\n",
       "Name: level, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#위에서 잡은 7 합치기 & train에 있는 경우는 사용하지 않기\n",
    "only = pd.read_csv(\"tem_answer.csv\")\n",
    "le7 = list(only[only['level']==7]['id'])\n",
    "le7_update = list((set(le7))-set(not7_id))\n",
    "print(len(le7))\n",
    "print(len(le7_update))\n",
    "idx = submission[submission['id'].isin(le7_update)].index\n",
    "submission.iloc[idx] = 7\n",
    "submission['level'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1002512\n",
       "1     396348\n",
       "3      12915\n",
       "5       6467\n",
       "7        581\n",
       "4         34\n",
       "2         34\n",
       "6         25\n",
       "Name: level, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "who = submission.level\n",
    "submission=pd.read_csv('sample_submission.csv')\n",
    "submission['level'] = who\n",
    "submission['level'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"final_answer.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
